{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weighted average ensembles assume that some models in the ensemble have more skill than others and give them more contribution when making predictions\n",
    "- The weighted average or weighted sum ensemble is an extension over voting ensembles that assume all models are equally skillful and make the same proportional contribution to predictions made by the ensemble\n",
    "- A limitation of the voting ensemble technique is that it assumes that all models in the ensemble are equally effective. This may not be the case as some models may be better than others, especially if different machine learning algorithms are used to train each model ensemble member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suraj\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Suraj\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Suraj\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8896969696969697, 0.8593939393939394, 0.8812121212121212]\n",
      "Weighted Avg Accuracy: 90.800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    " \n",
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr', LogisticRegression()))\n",
    "    models.append(('cart', DecisionTreeClassifier()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    " \n",
    "# evaluate each base model\n",
    "def evaluate_models(models, X_train, X_val, y_train, y_val):\n",
    "    # fit and evaluate the models\n",
    "    scores = list()\n",
    "    for name, model in models:\n",
    "        # fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate the model\n",
    "        yhat = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, yhat)\n",
    "        # store the performance\n",
    "        scores.append(acc)\n",
    "        # report model performance\n",
    "    return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.50, random_state=1)\n",
    "# split the full train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train, X_val, y_train, y_val)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingClassifier(estimators=models, voting='soft', weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_full, y_train_full)\n",
    "# make predictions on test set\n",
    "yhat = ensemble.predict(X_test)\n",
    "# evaluate predictions\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Weighted Avg Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8896969696969697, 0.8612121212121212, 0.8812121212121212]\n",
      "Weighted Avg Accuracy: 90.780\n",
      ">lr: 87.800\n",
      ">cart: 88.400\n",
      ">bayes: 87.300\n",
      "Voting Accuracy: 90.680\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    " \n",
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr', LogisticRegression()))\n",
    "    models.append(('cart', DecisionTreeClassifier()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    " \n",
    "# evaluate each base model\n",
    "def evaluate_models(models, X_train, X_val, y_train, y_val):\n",
    "    # fit and evaluate the models\n",
    "    scores = list()\n",
    "    for name, model in models:\n",
    "        # fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate the model\n",
    "        yhat = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, yhat)\n",
    "        # store the performance\n",
    "        scores.append(acc)\n",
    "        # report model performance\n",
    "    return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.50, random_state=1)\n",
    "# split the full train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train, X_val, y_train, y_val)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingClassifier(estimators=models, voting='soft', weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_full, y_train_full)\n",
    "# make predictions on test set\n",
    "yhat = ensemble.predict(X_test)\n",
    "# evaluate predictions\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Weighted Avg Accuracy: %.3f' % (score*100))\n",
    "# evaluate each standalone model\n",
    "scores = evaluate_models(models, X_train_full, X_test, y_train_full, y_test)\n",
    "for i in range(len(models)):\n",
    "    print('>%s: %.3f' % (models[i][0], scores[i]*100))\n",
    "# evaluate equal weighting\n",
    "ensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble.fit(X_train_full, y_train_full)\n",
    "yhat = ensemble.predict(X_test)\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Voting Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
